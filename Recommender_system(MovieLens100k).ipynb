{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems\n",
    "\n",
    "This is my attempt on building a recommender systems on MovieLens Dataset (100K)\n",
    "\n",
    "About dataset : [http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data \n",
    "\n",
    "data = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how the data looks\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a presence of null values?\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n",
      "\n",
      "Description about ratings:\n",
      "count    100004.000000\n",
      "mean          3.543608\n",
      "std           1.058064\n",
      "min           0.500000\n",
      "25%           3.000000\n",
      "50%           4.000000\n",
      "75%           4.000000\n",
      "max           5.000000\n",
      "Name: rating, dtype: float64\n",
      "\n",
      "Unique ratings: [0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5 5. ]\n",
      "\n",
      "Unique #users: 671\n",
      "\n",
      "Unique #movies: 9066\n"
     ]
    }
   ],
   "source": [
    "# Let's do some very basic checks before moving forward\n",
    "\n",
    "print ('Is there a presence of null values?\\n{}'.format(data.isnull().sum()))\n",
    "\n",
    "print ('\\nDescription about ratings:\\n{}'.format(data['rating'].describe()))\n",
    "\n",
    "unique_rating = data['rating'].unique()\n",
    "unique_rating.sort()\n",
    "print ('\\nUnique ratings: {}'.format(unique_rating))\n",
    "\n",
    "print ('\\nUnique #users: {}'.format(data['userId'].unique().shape[0]))\n",
    "\n",
    "print ('\\nUnique #movies: {}'.format(data['movieId'].unique().shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we have few utility functions that'll help us in the regression model for recommender systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions \n",
    "\n",
    "def train_test_split(df,way):\n",
    "    '''This function will perform train and test split of the data'''\n",
    "    if(way=='random'):\n",
    "        df = df.sample(frac=1)\n",
    "    elif(way=='time'):\n",
    "        df = df.sort_values(by='timestamp')\n",
    "    l = int(df.shape[0]*.8)\n",
    "    train = df[:l]\n",
    "    test = df[l:]\n",
    "    \n",
    "    X_train = train.drop(labels=['timestamp','rating'],axis=1); y_train = train['rating']\n",
    "    X_test = test.drop(labels=['timestamp','rating'],axis=1); y_test = test['rating']\n",
    "\n",
    "    return (X_train,y_train,X_test,y_test)\n",
    "\n",
    "def center_scale(train,test,fet):\n",
    "    '''This function takes in the test and train data and standardizes them'''\n",
    "    fet_col = train[fet].tolist()\n",
    "    mu = np.mean(fet_col); sig = np.std(fet_col)\n",
    "    \n",
    "    for i in range(len(fet_col)):\n",
    "        fet_col[i] = (fet_col[i]-mu)/sig\n",
    "    train[fet] = fet_col\n",
    "    fet_col = test[fet].tolist()\n",
    "    \n",
    "    for i in range(len(fet_col)):\n",
    "        fet_col[i] = (fet_col[i]-mu)/sig\n",
    "    test[fet] = fet_col\n",
    "    \n",
    "    return (train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test in a random fashion\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(data,'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanjay\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:52: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2afc135e3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code below plots the histogram of the ratings BLACK is training set BLUE is testing set\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "bins = unique_rating.tolist() + [5.5]\n",
    "plt.hist(x=[y_train,y_test],bins=bins,color=['black','blue'],normed=True,rwidth=0.9)\n",
    "plt.xticks(unique_rating+.25,unique_rating)\n",
    "plt.title('Histogram of Ratings',fontdict={'fontsize':30})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the distribution of ratings over the train and test data are same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender system using regression\n",
    "\n",
    "We are going to implement recommender system using regression techniques and record the metrics accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Standardizing these columns===\n",
      "\n",
      "userId\tmovieId\t"
     ]
    }
   ],
   "source": [
    "# Now we would standardize our train and test data \n",
    "\n",
    "print ('===Standardizing these columns===\\n')\n",
    "for i, cn in enumerate(X_train[X_train.columns]):\n",
    "    print (cn,end='\\t')\n",
    "    X_train, X_test = center_scale(X_train,X_test,cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we have functions that'll help us build the regression model and print the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms \n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def metric(observed, predicted):\n",
    "    rmse = mean_squared_error(observed,predicted)**0.5\n",
    "    mae = mean_absolute_error(observed,predicted)\n",
    "    print ('\\nRMSE: {}\\nMAE: {}'.format(rmse,mae))\n",
    "    \n",
    "def ridge_regressor(X_train,X_test,y_train,param):\n",
    "    '''Implements Ridge regression with hyperparameter tuning'''\n",
    "    \n",
    "    ridge = Ridge()\n",
    "    reg = GridSearchCV(ridge,param)\n",
    "    reg.fit(X_train,y_train)\n",
    "\n",
    "    rid_parameters = ridge.get_params()\n",
    "    rid_parameters['alpha'] = reg.best_params_['alpha']\n",
    "\n",
    "    ridge.set_params(**rid_parameters)\n",
    "    print ('\\n---Parameters for Ridge Regression---\\n{}'.format(ridge.get_params))\n",
    "\n",
    "    ridge.fit(X_train,y_train)\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    \n",
    "    return (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Parameters for Ridge Regression---\n",
      "<bound method BaseEstimator.get_params of Ridge(alpha=100, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)>\n",
      "\n",
      "===METRICS===\n",
      "\n",
      "RMSE: 1.066698503735705\n",
      "MAE: 0.8563265025436632\n",
      "\n",
      "Time required = 0:00:00.770394\n"
     ]
    }
   ],
   "source": [
    "# Lets try a our naive 1st cut solution which is a very simple form of ridge regression with hyper parameter tuning\n",
    "\n",
    "initial = datetime.datetime.now()\n",
    "\n",
    "#alpha = [0.125,0.25,0.5,1,2,4,8] # We had previously tried on this range. Now I would like to explore a larger range.\n",
    "alpha = [0.001,0.01,0.1,1,10,100]\n",
    "parameter = {'alpha':alpha}\n",
    "\n",
    "y_pred = ridge_regressor(X_train,X_test,y_train,parameter)\n",
    "\n",
    "print ('\\n===METRICS===')\n",
    "metric(y_test,y_pred)\n",
    "\n",
    "final = datetime.datetime.now()\n",
    "\n",
    "print ('\\nTime required =',final-initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above metrics are for the 1st cut solution of the recommender system implementation. With a MAE of 0.85, it's not a bad start. Let's see what else we can do with our models and let's also monitor the metrics of other different models.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender system using regression and a little bit of feature engineering\n",
    "\n",
    "We are going to try to modify the previous model by doing some sort of feature engineering on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we have 2 functions that create user and movie features. Read the function documentation to understand what they are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for feature engineering \n",
    "\n",
    "def user_features(df):\n",
    "    '''This function will create 2 user dependent features such as \n",
    "        the mean ratings given by the user and the std dev of the ratings'''\n",
    "    userid = df['userId'].tolist()\n",
    "    mean_ratings = list(); stddev_ratings = list()\n",
    "    for uid in userid:\n",
    "        uid_df = df.loc[df['userId']==uid]\n",
    "        ratings = uid_df['rating'].tolist()\n",
    "        mean = np.mean(ratings); std_dev = np.std(ratings)\n",
    "        \n",
    "        mean_ratings.append(mean); stddev_ratings.append(std_dev)\n",
    "        \n",
    "    df['mean_ratings_u'] = mean_ratings\n",
    "    df['stddev_ratings_u'] = stddev_ratings\n",
    "    \n",
    "    return df\n",
    "\n",
    "def movie_features(df):\n",
    "    '''This function will create 2 movie dependent features such as the \n",
    "        mean ratings that the movie got and the std dev of the ratings that the movie got'''\n",
    "    movid = df['movieId'].tolist()\n",
    "    mean_ratings = list(); stddev_ratings = list()\n",
    "    for mid in movid:\n",
    "        mid_df = df.loc[df['movieId']==mid]\n",
    "        ratings = mid_df['rating'].tolist()\n",
    "        mean = np.mean(ratings); std_dev = np.std(ratings)\n",
    "        \n",
    "        mean_ratings.append(mean); stddev_ratings.append(std_dev)\n",
    "        \n",
    "    df['mean_ratings_m'] = mean_ratings\n",
    "    df['stddev_ratings_m'] = stddev_ratings\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to reload the data before feature engineering\n",
    "\n",
    "data = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time required = 0:01:49.870061\n"
     ]
    }
   ],
   "source": [
    "# Feature enginnering \n",
    "\n",
    "initial = datetime.datetime.now()\n",
    "\n",
    "data = user_features(data) # this will add user-dependent features \n",
    "\n",
    "data = movie_features(data) # this will add movie-dependent features\n",
    "\n",
    "final = datetime.datetime.now()\n",
    "\n",
    "print ('\\nTime required =',final-initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>mean_ratings_u</th>\n",
       "      <th>stddev_ratings_u</th>\n",
       "      <th>mean_ratings_m</th>\n",
       "      <th>stddev_ratings_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.864581</td>\n",
       "      <td>3.178571</td>\n",
       "      <td>0.829669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.864581</td>\n",
       "      <td>3.702381</td>\n",
       "      <td>0.859537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.864581</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>0.762409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.864581</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>0.801204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.864581</td>\n",
       "      <td>4.260870</td>\n",
       "      <td>0.870651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp  mean_ratings_u  stddev_ratings_u  \\\n",
       "0       1       31     2.5  1260759144            2.55          0.864581   \n",
       "1       1     1029     3.0  1260759179            2.55          0.864581   \n",
       "2       1     1061     3.0  1260759182            2.55          0.864581   \n",
       "3       1     1129     2.0  1260759185            2.55          0.864581   \n",
       "4       1     1172     4.0  1260759205            2.55          0.864581   \n",
       "\n",
       "   mean_ratings_m  stddev_ratings_m  \n",
       "0        3.178571          0.829669  \n",
       "1        3.702381          0.859537  \n",
       "2        3.545455          0.762409  \n",
       "3        3.312500          0.801204  \n",
       "4        4.260870          0.870651  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the data now.\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are now 4 extra columns \n",
    "* mean_ratings_u: is the mean rating given by that particular user\n",
    "* stddev_ratings_u: is the standard deviation of the ratings given by that user\n",
    "* mean_ratings_m:  is the mean ratings that particular movie got\n",
    "* stddev_ratings_m: is the standard deviation of the ratings that a particular movie got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are spillting the data into train and test set in random fashion\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(data,'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Standardizing these columns===\n",
      "\n",
      "userId\tmovieId\tmean_ratings_u\tstddev_ratings_u\tmean_ratings_m\tstddev_ratings_m\t"
     ]
    }
   ],
   "source": [
    "# Now we would standardize our train and test data \n",
    "\n",
    "print ('===Standardizing these columns===\\n')\n",
    "for i, cn in enumerate(X_train[X_train.columns]):\n",
    "    print (cn,end='\\t')\n",
    "    X_train, X_test = center_scale(X_train,X_test,cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Parameters for Ridge Regression---\n",
      "<bound method BaseEstimator.get_params of Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)>\n",
      "\n",
      "===METRICS===\n",
      "\n",
      "RMSE: 0.8337655216879091\n",
      "MAE: 0.6387381172964315\n",
      "\n",
      "Time required = 0:00:00.305771\n"
     ]
    }
   ],
   "source": [
    "# Trying out the same algorithm for ridge regression after feature engineering \n",
    "\n",
    "initial = datetime.datetime.now()\n",
    "\n",
    "#alpha = [0.125,0.25,0.5,1,2,4,8] # We had previously tried on this range. Now I would like to explore a larger range.\n",
    "alpha = [0.001,0.01,0.1,1,10,100]\n",
    "parameter = {'alpha':alpha}\n",
    "\n",
    "y_pred = ridge_regressor(X_train,X_test,y_train,parameter)\n",
    "\n",
    "print ('\\n===METRICS===')\n",
    "metric(y_test,y_pred)\n",
    "\n",
    "final = datetime.datetime.now()\n",
    "\n",
    "print ('\\nTime required =',final-initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the above metric. Previously we had a MAE of ~ 0.85 now we have around 0.63 which is a very significant increase in the performance. Hence we can say our feature engineering really works.\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-user similarity based recommender system\n",
    "\n",
    "Here I have implemented the user-user similarity based recommender system completely from scratch.\n",
    "<br>I'm defining user A and B as similar users if they have common movies that they have rated (this should include the movie that is our current test point)\n",
    "<br>Degree similarity between two users is the eucledian distance determined by the rating vector of common movies. Lower the distance, greater is the similarity.\n",
    "<br>Predicted rating would be the mean rating of the most similar users on the test movie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below I have some utility functions that I made that'll help me implement the user-user similarity recommender system. The descriptions about the functions are given in the function documentation itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for recommending engine \n",
    "\n",
    "\n",
    "def eliminate_users(df, threshold):\n",
    "    '''This function will eliminate those users who haven't rated atleast \"threshold\" movies '''\n",
    "    unique_uids = df['userId'].unique().tolist()\n",
    "    for uid in unique_uids:\n",
    "        uid_df = df.loc[df['userId']==uid]\n",
    "        if(uid_df.shape[0]<threshold):\n",
    "            df = df.loc[df['userId']!=uid]\n",
    "            \n",
    "    return df\n",
    "\n",
    "def eliminate_movie(df, threshold):\n",
    "    '''This function will eliminate those movies which havent been rated atleast \"threshold\" times'''\n",
    "    unique_mids = df['movieId'].unique().tolist()\n",
    "    for mid in unique_mids:\n",
    "        mid_df = df.loc[df['movieId']==mid]\n",
    "        if(mid_df.shape[0]<threshold):\n",
    "            df = df.loc[df['movieId']!=mid]\n",
    "            \n",
    "    return df\n",
    "\n",
    "def create_ds(df):\n",
    "    '''This will create a dictionary where the key will the userid and the \n",
    "        content will be a set of the movieid that a particular user has rated'''\n",
    "    content_dict = dict()\n",
    "    unique_uids = df['userId'].unique().tolist()\n",
    "    for uid in unique_uids:\n",
    "        uid_df = df.loc[df['userId']==uid]\n",
    "        mids = uid_df['movieId'].unique()\n",
    "        content_dict[uid] = set(mids)\n",
    "        \n",
    "    return content_dict\n",
    "\n",
    "def get_distance(x, y):\n",
    "    '''This will return the eucledian distance between x and y'''\n",
    "    if (len(x)!= len(y)):\n",
    "        print ('error')\n",
    "    \n",
    "    x = np.array(x); y = np.array(y)\n",
    "\n",
    "    return (np.sqrt(np.sum((x-y)**2)))\n",
    "\n",
    "def get_similar_user(uid, mid, index):\n",
    "    '''This function will return all the users which are similar to uid\n",
    "        and similarity is determined if they have atleast 10 movies in common including mid'''\n",
    "    mset = index[uid]; similar_uid = list()\n",
    "    for other_uid in index.keys():\n",
    "        if(other_uid != uid and mid in index[other_uid]):\n",
    "            other_mset = index[other_uid]\n",
    "            if(len(mset.intersection(other_mset))>=10):\n",
    "                similar_uid.append(other_uid)\n",
    "                \n",
    "    return similar_uid\n",
    "\n",
    "def get_similarity_degree(uid, mid, similar_uid, index, df):\n",
    "    '''This will return the similarity degree between uid and the similar_users\n",
    "        similarity degree is determined the eucledian distance of the ratings of the common movie'''\n",
    "    similarity_degree = list()\n",
    "    for other_uid in similar_uid:\n",
    "        intersection_point = index[uid].intersection(index[other_uid])\n",
    "        #print (intersection_point)\n",
    "        intersection_point = list(intersection_point); a = []; b = []\n",
    "        for i in intersection_point:\n",
    "            if(i != mid):\n",
    "                rating_a =  df[(uid,i)] # df.loc[df['movieId'] == i]; rating_a = rating_a.loc[rating_a['userId'] == uid]\n",
    "                rating_b =  df[(other_uid,i)] # df.loc[df['movieId'] == i]; rating_b = rating_b.loc[rating_b['userId'] == other_uid]\n",
    "                a.append(rating_a); b.append(rating_b)\n",
    "\n",
    "        similarity_degree.append(get_distance(a,b))        \n",
    "            \n",
    "    return similarity_degree\n",
    "\n",
    "def convert_dataframe(df):\n",
    "    uid = df['userId'].tolist()\n",
    "    mid = df['movieId'].tolist()\n",
    "    rating = df['rating'].tolist()\n",
    "    \n",
    "    dataframe_dict = dict()\n",
    "    \n",
    "    for i in range(len(uid)):\n",
    "        dataframe_dict[(uid[i],mid[i])] = rating[i]\n",
    "        \n",
    "    return dataframe_dict\n",
    "\n",
    "def predict_rating(distance_vector, SIMILAR_USERS, mid, df, tth_percentile):\n",
    "    ''' this function will get the most similar users from the similar users (determined by applying the\n",
    "        threshold on the eucledian distance) and then find what ratings they gave to the test rating and return\n",
    "        prediction as their mean'''\n",
    "    try:\n",
    "        threshold = np.percentile(distance_vector,tth_percentile)\n",
    "    except: \n",
    "        return \"ERROR\"\n",
    "\n",
    "    most_similar = list()\n",
    "\n",
    "    for i in range(len(distance_vector)):\n",
    "        if(distance_vector[i] <= threshold):\n",
    "            most_similar.append(SIMILAR_USERS[i])\n",
    "\n",
    "    rating_vector = list()\n",
    "\n",
    "    for i in range(len(most_similar)):\n",
    "        flag = df[(most_similar[i],mid)] # flag = df.loc[df['userId']==most_similar[i]]\n",
    "                                         # flag = flag.loc[flag['movieId']==mid]\n",
    "        rating_vector.append(flag)\n",
    "\n",
    "    return (np.mean(rating_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the data as it's a fresh approach to recommender systems\n",
    "\n",
    "data = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First parameter for this implemetation, this is for the number of movies that a user needs to rate atleast and the minimum number of ratings a movie must have inorder to be considered by this algorithm\n",
    "\n",
    "param1 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size before the operation --- 100004\n",
      "\n",
      "Size after the operation --- 81915\n"
     ]
    }
   ],
   "source": [
    "print ('Size before the operation --- {}'.format(data.shape[0]))\n",
    "\n",
    "# Eliminating users who haven't rated atleast  param1 movies\n",
    "data = eliminate_users(data,param1)\n",
    "\n",
    "# Eliminating movies that haven't been rated atleast param1 times\n",
    "data = eliminate_movie(data,param1)\n",
    "\n",
    "print ('\\nSize after the operation --- {}'.format(data.shape[0]))\n",
    "\n",
    "# Now we will create a dictionary where the key will be the userIds and the content will be set of the movieId that the user has rated\n",
    "index = create_ds(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# Here we will convert the information in our dataframe to a dictionary for much faster access\n",
    "# dict format: \n",
    "# key = (userId, movieID); value = rating\n",
    "\n",
    "data_dict = convert_dataframe(data)\n",
    "\n",
    "# Lets see how the data looks\n",
    "print (data_dict[1,1029]) # userId = 1 and movieId = 1029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd parameter in this implementation, this is the nth percentile that'll separate the most similar users from the set of all similar users\n",
    "\n",
    "param2 = 75 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The main purpose of the caller_func() is to integrate the previous utility functions.\n",
    "\n",
    "def caller_func():\n",
    "    '''This caller function will pick a random point from the dataframe and treat it as a test point.\n",
    "    It'll get the similar users, degree of similarity and then predict rating '''\n",
    "    test_point = data.sample(n=1)\n",
    "    test_uid = int(test_point['userId']); test_mid = int(test_point['movieId'])\n",
    "\n",
    "    similar_users = get_similar_user(test_uid,test_mid,index)\n",
    "\n",
    "    distances = get_similarity_degree(test_uid,test_mid,similar_users,index,data_dict)\n",
    "\n",
    "    #sns.distplot(distances)\n",
    "\n",
    "    observed = float(test_point['rating'])\n",
    "    predicted = predict_rating(distances,similar_users,test_mid,data_dict, param2) # param2 is the t-th percentile for choosing most-similar users\n",
    "    \n",
    "    if (predicted == \"ERROR\"):\n",
    "        return (\"ERROR\", \"ERROR\")\n",
    "    \n",
    "    return (observed,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE: 0.9421296447411392\n",
      "MAE: 0.723495951243854\n",
      "\n",
      "Time required = 0:02:23.270263\n"
     ]
    }
   ],
   "source": [
    "initial = datetime.datetime.now()\n",
    "\n",
    "n = int(0.2*data.shape[0]); # 20% of the total size\n",
    "obs = list(); pred = list()\n",
    "while(n>0): \n",
    "    n = n-1\n",
    "    o,p = caller_func()\n",
    "    if (o==\"ERROR\" or p == \"ERROR\"):\n",
    "        continue\n",
    "    obs.append(o); pred.append(p)\n",
    "    \n",
    "metric(obs,pred)\n",
    "\n",
    "final = datetime.datetime.now()\n",
    "\n",
    "print ('\\nTime required =',final-initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this implementation of our recommender system we are getting the above metrics when tested on random points 20% of the data ~ 16k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our implementation of user-user similarity based recommender system resulted in the above metrics. MAE of 0.72 is not at all a bad metric. My hypothesis is this results will improve as users start rating more number of movies as then the set of common movies would increase and it would be more easier to judge who is most similar and who isn't.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Matrix factorization model using Spotlight\n",
    "\n",
    "Credits: [https://github.com/maciejkula/spotlight] \n",
    "\n",
    "<br>\n",
    "\n",
    "Here I've used a library for matrix factorization which is called spotlight. You can find more about the library in the given link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.evaluation import rmse_score\n",
    "from spotlight.factorization.explicit import ExplicitFactorizationModel\n",
    "\n",
    "dataset = get_movielens_dataset(variant='100K')\n",
    "\n",
    "train, test = random_train_test_split(dataset)\n",
    "\n",
    "model = ExplicitFactorizationModel(n_iter=1)\n",
    "model.fit(train)\n",
    "\n",
    "rmse = rmse_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE: 1.003307580947876\n"
     ]
    }
   ],
   "source": [
    "print ('\\nRMSE: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
